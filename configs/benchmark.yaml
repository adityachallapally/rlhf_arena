# RLHF Arena Benchmark Configuration
# Multi-experiment orchestration and comparison

# Benchmark configuration
benchmark:
  name: "rlhf_arena_benchmark"
  description: "Comprehensive benchmark of RLHF algorithms"
  version: "1.0.0"
  author: "RLHF Arena Team"
  
  # Experiment settings
  experiment_timeout: 7200  # 2 hours per experiment
  max_retries: 2            # Maximum retry attempts for failed experiments
  early_stopping: true      # Stop if too many experiments fail
  
  # Resource management
  max_parallel: 2           # Maximum parallel experiments
  gpu_memory_limit: "24GB"  # GPU memory limit per experiment
  cpu_limit: 8              # CPU cores limit per experiment
  
  # Monitoring
  progress_update_interval: 300  # Progress update every 5 minutes
  health_check_interval: 60      # Health check every minute
  save_checkpoint_interval: 600  # Save checkpoint every 10 minutes

# Algorithms to test
algorithms:
  - "ppo"
  - "dpo"
  - "grpo"
  - "grpo_offpolicy"
  - "grpo_vi"
  - "rlaif"

# Datasets to test
datasets:
  - "hh"           # Anthropic HH
  - "oasst"        # OpenAssistant
  - "ultrafeedback" # UltraFeedback

# Model sizes to test
model_sizes:
  - "7b"           # 7B parameter models
  # - "13b"        # 13B parameter models (uncomment if you have enough GPU memory)
  # - "30b"        # 30B parameter models (uncomment if you have enough GPU memory)

# Experiment overrides for benchmark-specific settings
experiment_overrides:
  # Reduce training steps for faster benchmarking
  training.num_epochs: 5
  training.total_steps: 500
  
  # Smaller batch sizes for memory efficiency
  training.batch_size: 2
  training.gradient_accumulation_steps: 8
  
  # Faster evaluation
  evaluation.eval_steps: 100
  evaluation.num_eval_samples: 500
  
  # Reduced dataset size for faster experiments
  dataset.max_samples: 5000
  
  # Memory optimization
  hardware.gradient_checkpointing: true
  hardware.mixed_precision: "fp16"
  hardware.memory_efficient_attention: true

# Multi-objective experiments
multi_objective_experiments:
  enabled: true
  objectives:
    - "helpfulness"
    - "harmlessness"
  weight_combinations:
    - [0.7, 0.3]
    - [0.5, 0.5]
    - [0.3, 0.7]

# Hyperparameter search
hyperparameter_search:
  enabled: false  # Set to true for hyperparameter optimization
  method: "optuna"
  n_trials: 10
  search_space:
    learning_rate: [1e-6, 1e-4]
    batch_size: [1, 4]
    clip_ratio: [0.1, 0.3]
    beta: [0.05, 0.2]  # For DPO

# Evaluation metrics
evaluation_metrics:
  primary:
    - "reward_mean"
    - "sample_efficiency"
    - "training_duration"
  
  secondary:
    - "kl_divergence"
    - "entropy"
    - "memory_usage"
    - "gpu_efficiency"
  
  custom:
    - "convergence_rate"
    - "stability_score"
    - "robustness_index"

# Reporting and visualization
reporting:
  # Output formats
  formats:
    - "json"
    - "csv"
    - "html"
    - "pdf"
  
  # Charts to generate
  charts:
    - "performance_comparison"
    - "learning_curves"
    - "dataset_comparison"
    - "algorithm_ranking"
    - "efficiency_analysis"
    - "memory_usage_trends"
  
  # Statistical analysis
  statistics:
    - "mean"
    - "std"
    - "median"
    - "quartiles"
    - "confidence_intervals"
    - "significance_tests"

# Quality assurance
quality_assurance:
  # Data validation
  validate_results: true
  min_experiment_count: 3  # Minimum experiments per algorithm-dataset combination
  
  # Outlier detection
  outlier_detection: true
  outlier_threshold: 3.0   # Standard deviations
  
  # Consistency checks
  consistency_checks: true
  reward_range: [0.0, 1.0]
  duration_range: [0.1, 24.0]  # hours
  
  # Reproducibility
  save_random_seeds: true
  save_environment_info: true
  save_hardware_specs: true

# Resource monitoring
resource_monitoring:
  # System metrics
  track_cpu: true
  track_memory: true
  track_gpu: true
  track_disk: true
  track_network: true
  
  # Application metrics
  track_training_time: true
  track_memory_usage: true
  track_gpu_utilization: true
  track_sample_efficiency: true
  
  # Alerting
  alerts:
    gpu_memory_threshold: 0.9  # Alert at 90% GPU memory usage
    cpu_usage_threshold: 0.8   # Alert at 80% CPU usage
    experiment_timeout_threshold: 0.8  # Alert at 80% of timeout

# Logging and debugging
logging:
  level: "INFO"
  format: "detailed"
  
  # File logging
  file_logging: true
  log_rotation: true
  max_log_size: "100MB"
  max_log_files: 10
  
  # Experiment logging
  log_experiment_details: true
  log_resource_usage: true
  log_error_details: true
  
  # Performance logging
  log_timing: true
  log_memory: true
  log_gpu: true

# Checkpointing and recovery
checkpointing:
  # Benchmark state
  save_benchmark_state: true
  save_interval: 300  # Save every 5 minutes
  
  # Experiment checkpoints
  save_experiment_checkpoints: true
  checkpoint_interval: 600  # Save every 10 minutes
  
  # Recovery
  auto_resume: true
  resume_from_latest: true
  
  # Cleanup
  cleanup_old_checkpoints: true
  max_checkpoints: 10

# Advanced features
advanced:
  # Distributed training
  distributed_training: false
  num_nodes: 1
  num_gpus_per_node: 1
  
  # Mixed precision
  mixed_precision: true
  precision_mode: "fp16"
  
  # Gradient accumulation
  gradient_accumulation: true
  accumulation_steps: 8
  
  # Memory optimization
  memory_optimization: true
  gradient_checkpointing: true
  attention_optimization: true
  
  # Caching
  enable_caching: true
  cache_dir: "cache/"
  cache_size: "10GB"

# Post-processing
post_processing:
  # Result aggregation
  aggregate_results: true
  aggregation_method: "weighted_average"
  
  # Statistical analysis
  statistical_analysis: true
  confidence_level: 0.95
  
  # Ranking algorithms
  algorithm_ranking: true
  ranking_metrics: ["reward_mean", "sample_efficiency", "training_duration"]
  ranking_weights: [0.5, 0.3, 0.2]
  
  # Generate insights
  generate_insights: true
  insight_types:
    - "performance_trends"
    - "algorithm_comparisons"
    - "dataset_analysis"
    - "resource_optimization"
    - "recommendations"

# Export and sharing
export:
  # Export formats
  formats:
    - "json"
    - "csv"
    - "excel"
    - "html"
    - "pdf"
  
  # Export location
  export_dir: "exports/"
  
  # Sharing
  share_results: false
  share_method: "local"  # local, s3, gcs, azure
  
  # Documentation
  generate_documentation: true
  documentation_format: "markdown"
  include_charts: true
  include_code: false 